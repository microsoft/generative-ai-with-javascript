# Glossary

A comprehensive list of technical terms used throughout the lessons.

- **API (Application Programming Interface)**: A set of rules enabling software applications to communicate with each other, commonly used in generative AI integration.
- **API key**: A private key used to authenticate requests to an application programming interface.
- **Augmented Prompt**: A prompt enhanced with additional context or information to improve the relevance of AI-generated responses.
- **Azure AI Studio**: A platform to build, evaluate, and deploy AI models using Microsoft Azure.
- **Azure OpenAI**: A cloud service for deploying and scaling OpenAI models like GPT for applications.
- **Caesar cipher**: A substitution cipher shifting characters by a fixed number of places in the alphabet.
- **Chain-of-Thought Prompting**: A technique guiding models to break down complex tasks into sequential reasoning steps for better accuracies in outputs.
- **Chatbot**: An application designed to simulate conversation with human users, often using natural language processing.
- **Completions API**: API to generate text or code based on inputs, used for predictive or generative tasks in AI models.
- **Context Window**: The amount of past input that a language model can consider when generating responses, measured in tokens.
- **CSV (Comma-Separated Values)**: A data format consisting of values separated by commas, often used for structured data retrieval and modification.
- **Embedding**: Numeric vector representation of data, often used for semantic search or clustering in machine learning.
- **Escape Hatch**: A technique instructing AI to admit lack of knowledge when data is insufficient to ensure accurate responses.
- **Few-Shot Prompting**: A method of providing minimal examples to the model to influence its output with specific context or format.
- **Full-Stack Development**: Development of both the client (frontend) and server (backend) in software applications.
- **Function Calling**: A method for passing structured prompt data into specific functions within an application programmatically.
- **GitHub Codespaces**: A cloud-based environment for coding, testing, and running applications directly from GitHub repositories.
- **GitHub Models**: A platform hosting pre-trained AI models for use and integration with GitHub development workflows.
- **GitHub Token**: An authentication method to access GitHub-hosted APIs or services securely.
- **IDE (Interactive Development Environment)**: Software providing coding, debugging, and testing tools for developers.
- **JSON (JavaScript Object Notation)**: A lightweight data-interchange format used for structured information exchange between systems, including generative AI responses.
- **Knowledge Bases**: Data repositories used to enhance AI applications by providing reliable, domain-specific information.
- **LangChain**: A framework for building AI applications that focus on chaining multiple models and functionalities together.
- **LLM (Large Language Model)**: AI models trained on large text datasets to generate human-like responses for diverse applications.
- **Maieutic Prompting**: A technique involving follow-up queries to challenge or validate AI-generated responses for accuracy and reasoning.
- **Managed Identity**: A secure cloud mechanism that provides applications with automatic authentication to access resources without managing passwords.
- **Markdown**: A lightweight markup language for formatting plain text into structured layouts, like tables or lists.
- **MCP (Model Context Protocol)**: A protocol to decentralize applications by separating server capabilities and connection protocols.
- **Meta Prompts**: Instructions added before a user's prompt to refine or restrict the AI's behavior and output format.
- **Multimodal Capabilities**: AI functionality to process various formats like text, image, or video input and deliver diverse outputs.
- **Node.js**: A runtime environment allowing developers to execute JavaScript code server-side for building scalable applications.
- **OpenAI**: A pioneering organization in AI research and APIs for language models integrated into applications for generative tasks.
- **Prompt Engineering**: The process of crafting effective prompts to guide AI models toward desired responses and behaviors.
- **RAG (Retrieval-Augmented Generation)**: A technique combining retrieval-based methods with generative models for more accurate, data-grounded outputs.
- **Semantic Search**: Search method leveraging the meaning of terms for more contextually accurate and nuanced results.
- **Structured Output**: Data output organized in predefined formats like tables or JSON, enabling easier integration with systems.
- **System Message**: A prompt in conversational AI that specifies contextual boundaries or personality for the assistant.
- **TensorFlow.js**: A JavaScript-based machine learning library enabling browser and Node.js-based AI/ML applications and training.
- **Tokenizer**: A tool used to convert text into tokens, providing structure for how data is inputted or analyzed by models.
- **Vector Search**: Retrieval technique comparing encoded vectors to find semantically similar information in AI applications.
- **XML (eXtensible Markup Language)**: A markup language formatting structured data for information storage, exchange, or generative model input/output.

## Technical Terms

The following terms should NOT be translated:

- prompt
